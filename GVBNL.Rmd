---
title: "Legacy Sales - GrandVision Benelux - "
author: "F.J.Padt"
date: "`r Sys.Date()`"
output: 
   pdf_document:
    toc:             true
    toc_depth:       2
    number_sections: true
    fig_caption:     true
    fig_crop:        true
    highlight:       tango    
---

\newpage
![Logo](http://www.grandvision.com/img/logoGV.png) 

[DESIGN](https://projects.gvshare.com/iSynergy/01_Release_1/06._Reporting/02._Design/01._FDs/R20_POS Sales - Margin/)

```{r RSetup, echo=FALSE, eval=TRUE, cache=FALSE, results='hide'}

rm(list=ls())
gc()

source('../QAR/00_RProj/00_Global/iSynGeneral.R')


# Data Settings
fECHO    <- TRUE
fEVAL    <- TRUE
fRESULTS <- 'hide' 
fIMAGE   <- TRUE 

# SAP systems to use
pECC_SYST <- "RP1"
pECC_CLNT <- "300"
pBI_SYST  <- "BP1" 
pBI_CLNT  <- "300"
pLGCINDC  <- "C"

# Data Settings
pOPCO     <- "GVBNL"
pARTGRP   <- c("CL")
pROWS     <- -1L
pSMALL    <- 1000
pEXMP     <- 50 
pEXP      <- FALSE
pPath     <- "./60_Results" 
pXLSX     <- paste0(pOPCO, "_SALES_", pARTGRP) 
pEXPORT   <- paste0("POS_HISTORY" , ".csv") 

# Open Excel for storing results
if(file.exists(paste0(pPath, "/", pXLSX, ".xlsx")) == TRUE){
   file.remove(paste0(pPath, "/", pXLSX, ".xlsx"))
}

fWriteToSheet(data.frame(ECCSYST = pECC_SYST, 
                         ECCCLNT = pECC_CLNT,
                         BI_SYST = pBI_SYST ,
                         BI_CLNT = pBI_CLNT), 
              pPath, pXLSX, "PARAM", pAppend = FALSE )
```

```{r ReadRawData, echo=fECHO, eval=fEVAL}

vSORG <- c("BE01", "BE02", "BE11", "NL01", "NL02", "NL07", "NL14")
vDCHN <- c("10", "20", "30")

# Material - Read the MEAN table whcih contains the mapping
dtMEAN       <- fGetEXPTable(pTable  = "MEAN", pKey = c("MATNR", "MEINH"),
                             pSystID = pECC_SYST, pClient = pECC_CLNT)
dtMEAN       <- dtMEAN[, MATNR:= as.character(MATNR)]

# MAT_SALES for Account assignment Group


dtTVKMT      <- fGetEXPTable(pTable  = "TVKMT", pKey = c("KTGRM"),
                             pSystID = pECC_SYST, pClient = "300")
dtTVKMT      <- dtTVKMT[ SPRAS == "E", .(KTGRM, VTEXT)]

dtPLANT      <- fGetEXPTable(pTable  = "#BI0#PPLANT",
                             pKey    = "PLANT",
                             pSystID = pBI_SYST, pClient = "300")
setnames(dtPLANT, gsub("^/BIC/", "", colnames(dtPLANT)  ))

# special for NL a table with the time intervals
dtPLANTT    <- fread(input = "./RAW_DATA/GVBNL_PLANTT.csv", sep = ";",
                     colClasses = "character", stringsAsFactors = FALSE)

#Load transactional data
dtDATA     <- fread(file.path(".", "RAW_DATA", "GVBLX_HIST.txt"),  
                    sep = ";", nrows = pROWS, colClasses="character") 

l_months <- sort(unique(substr(dtDATA$invoice_date, 1, 6)))
dtMonths <- dtDATA[, .N, by=.(substr(dtDATA$invoice_date, 1, 6))]

setnames(
  dtDATA,
  c("invoice_date", "store"         , "invoice_number" ,
    "order_type"  , "article_number", "discount_reason", 
    "link"        , "quantity"      , "discount"       , 
    "tax_amount"  , "cost_amount"   , "net_sales_incl_tax",
    "wholesale_price"),
  c("CALDAY"      , "G1LGSTNO"      , "BILL_NUM"       , 
    "RPA_TTC"     , "MATNR"         , "RPA_DRC"        , 
    "G1LINKV"     , "QUANTITY"      , "G1DISCIT"       , 
    "TAX_AMOUNT"  , "RETPRCOST"     , "NSITX",
    "RETTRCOST"))

```

# Historical Data #

The historical data for `r pOPCO` is extracted from Navison as one big data set. 
This set is turned into a  subset of the standard SAP extractor 
2LIS_13_VDITM which is used in the iSynery Project.

From:    `r min(dtDATA$SLSDATE)` 
To:      `r max(dtDATA$SLSDATE)`
Records: `r nrow(dtDATA)`

## Source Data 

```{r PrepareDataSet, echo=fECHO, eval=fEVAL, results=fRESULTS}
# check for Invalid Article numbers and replace those
# 20160530 -> 25 records
dtTMP01 <- dtDATA[MATNR == "00000000"]
fWriteToSheet(dtTMP01, 
              pPath, pXLSX, "MATNR_00000000", pAppend = TRUE)
dtDATA <- dtDATA[MATNR %in% dtTMP01$MATNR,  MATNR:= "CL0000"]

# 20160530 -> 2178 records
dtTMP01 <- dtDATA[MATNR  == " " |
                  MATNR  == ""  |  
                  (MATNR == 0)  ] 
fWriteToSheet(dtTMP01, 
              pPath, pXLSX, "MATNR_MISSING", pAppend = TRUE)

# en het lijkt allemaal ‘drukwerk’ te betreffen.
# Alles mag dus naar 180181 – Office printed
dtDATA <- dtDATA[MATNR %in% dtTMP01$MATNR, MATNR:= "NL0000"]

# remove leading zero's
dtDATA <- dtDATA[, MATNR:= sub("^0+", "", MATNR, perl = TRUE)]

gc()
if(fIMAGE){save.image(file = paste0("NLCL", 
                                    format(today(), "%Y%m%d"), 
                                    "_PrepareDataSet", ".RData" ))}
```

Below the structure of the source data and the number of records is displayed

```{r displayDetailMean, echo=fECHO, eval=fEVAL, results='markup'}

str(dtDATA)
head(dtDATA[, c(1:7)             , with = FALSE])
head(dtDATA[, c(8 :ncol(dtDATA)) , with = FALSE])

fWriteToSheet(head(dtDATA[1:pEXMP]), 
               pPath, pXLSX, "EXAMPLE_DATA_BEFORE"   , pAppend = TRUE)
```

```{r ChangeDataTypes, echo=fECHO, eval=fEVAL, results=fRESULTS}
# Change data Types and set NA to 0 !!!!  700secs. !!!!
system.time(
  dtDATA <- dtDATA[, `:=`(
    BILL_NUM       = paste0("H", 
                            str_pad(G1LGSTNO, 3, pad ="0", side = "left"), 
                            str_pad(BILL_NUM, 6, pad ="0", side = "left")),
    RPA_DRC        = toupper(x = RPA_DRC),
    G1LGSTNO       = str_pad(G1LGSTNO, 3, pad ="0"),
    QUANTITY       = ifelse(is.na(QUANTITY)  , 0, as.integer(QUANTITY)),
    NSITX          = ifelse(is.na(NSITX)     , 0, as.numeric(sub(",", ".", NSITX))),
    G1DISCIT       = ifelse(is.na(G1DISCIT)  , 0, as.numeric(sub(",", ".", G1DISCIT))),
    TAX_AMOUNT     = ifelse(is.na(TAX_AMOUNT), 0, as.numeric(sub(",", ".", TAX_AMOUNT))),
    RETPRCOST      = ifelse(is.na(RETPRCOST) , 0, as.numeric(sub(",", ".", RETPRCOST))), 
    ORGSCCOST      = ifelse(is.na(RETPRCOST) , 0, as.numeric(sub(",", ".", RETPRCOST))),
    RETTRCOST      = ifelse(is.na(RETTRCOST) , 0, as.numeric(sub(",", ".", RETTRCOST ))),
    DOC_CURRCY     = "EUR",
    UNIT           = "ST",
    RETAILTYPECODE =  NA,
    G1LISLINT      =  0,
    G1LOFLAG       =  NA,
    G1SPECFG       =  NA,
    G1WGHCMB       =  NA
    ) ]
  )

dtDATA <- dtDATA[, `:=`(NETVAL_INV = NSITX - TAX_AMOUNT)]
setkey(dtDATA, "BILL_NUM")

# Generate BILL_ITEM
system.time(
  dtDATA <- dtDATA[, BILL_ITEM:= str_pad(seq(from = 1, to = .N, by = 1), 
                                       width = 5, pad = "0"), 
                 by=c("BILL_NUM", "G1LGSTNO", "CALDAY")])

fWriteToSheet(head(dtDATA[1:pEXMP]), 
               pPath, pXLSX, "EXAMPLE_DATA_AFTER"   , pAppend = TRUE)
# save(dtDATA, file = paste0("dtDATA_", pARTGRP, ".RData"))

gc()
if (fIMAGE){save.image(file = paste0("NLCL", 
                                     format(today(), "%Y%m%d"), 
                                     "_ChangeDataTypes", ".RData" ))}
```

### Data Preparation

The column names of the GVBNL data are changed to the BI object names for Mapping.
Secondly the decimal separator ',' is replaced by a '.'.
Finally non-existing key figures or set to 0.

```{r displayDetailMean2, echo=fECHO, eval=fEVAL, results='markup'}
str(dtDATA)
head(dtDATA)

```

### Data Source

```{r LegacyStoreToSAP, echo=fECHO, eval=fEVAL, results=fRESULTS}

dtPLANT     <- dtPLANT[PLANTCAT == "A" & !(substr(PLANT, 1, 1) %in% c("Y", "Z"))
                       ][, `:=`(PLANTCAT = NULL, SYSTID = NULL)]

# add the iSynergy Store next to the legacy store

# PLANT
dtPLANT <- dtPLANT[SALESORG %in% c("NL01", "BE01", "NL02", "BE02", "NL14", "NL07") ]
setkey(dtPLANT, PLANT)

# Remove the "/BIC/" prefix
setnames(dtPLANT, gsub("^/BIC/", "", colnames(dtPLANT)))

dtPLANT <- dtPLANT[, CHK:= substr(G1LGSTNO, nchar(G1LGSTNO)-2, nchar(G1LGSTNO))]
dtPLANT <- dtPLANTT[dtPLANT, on = c("PLANT", "CHK"), .(PLANT, G1LGSTNO, SALESORG, DISTR_CHAN, CHK, FROM)]
dtPLANT <- dtPLANT[, `:=`(G1LGSTNO = CHK, CHK = NULL)]
dtPLANT <- dtPLANT[is.na(FROM), FROM:= "10000101"]

# Quality check on duplicate Legacy Stores
dtTMP02  <- copy(dtPLANT)
dtTMP02  <- dtTMP02[, DUP:= duplicated(dtTMP02, by = "G1LGSTNO")]
dtTMP02  <- dtTMP02[, DUP:= any(DUP)          , by = "G1LGSTNO" ]
dtTMP02  <- dtTMP02[DUP == TRUE ]
setkey(dtTMP02, "G1LGSTNO", "FROM") 

fWriteToSheet(dtTMP02, 
              pPath, pXLSX, "PLANT_DUP", pAppend = TRUE )

# check If any closed stores missing
dtTMP03 <- data.table(
  SALES_WO_SITE   = setdiff(unique(dtDATA$G1LGSTNO), dtPLANT$G1LGSTNO))
fWriteToSheet(dtTMP03, 
              pPath, pXLSX, "SALES_WO_SITE", pAppend = TRUE )

# Check Sites without sales, could be new
dtTMP04 <- data.table(
  SITE_WO_SALES = setdiff(dtPLANT$G1LGSTNO       , unique(dtDATA$G1LGSTNO)))
fWriteToSheet(dtTMP04, 
              pPath, pXLSX, "SITE_WO_POS_SALES", pAppend = TRUE )

# Map the data Of the Legacy Stores
setnames(dtPLANT, "FROM", "CALDAY")
system.time(
  dtDATA <- dtPLANT[dtDATA, roll = TRUE, rollends = TRUE, 
               on = c("G1LGSTNO", "CALDAY")])

gc()
if (fIMAGE){save.image(file = paste0("NLCL", 
                                     format(today(), "%Y%m%d"), 
                                     "_LegacyStoreToSAP", ".RData" ))}

```

## Article Mapping

```{r LegacyArticleMapping, echo=fECHO, eval=fEVAL}
# enhance the MEAN table with Reference articles and dummies
# this table can then be used to map teh articles in the sales data set

```



```{r LegacyArticleToSAP, echo=fECHO, eval=fEVAL }


# add the iSynergy Article next to the legacy article
dtMEANR3 <- dtMEAN[MEINH == "ST" & 
                  EANTP == "Z1" &
                  EAN11 != "DUPLICATE", 
                  .(MATNR, EAN11, EANTP)]
setnames(dtMEANR3, c("EAN11"), c("LMTNR"))
setkey(dtMEANR3, "MATNR", "LMTNR", "EANTP")
dtMEANR3 <- unique(dtMEANR3)

# Additional Mapping Mean NL - using iSynergy articles as Reference
dtMEANNL <- fread("./RAW_DATA/MEAN_NL.csv", colClasses = "character")
dtMEANNL[, MATNR:= str_pad(string = MATNR, width = 18, side = "left", pad = "0")]
setkey(dtMEANNL, "MATNR", "LMTNR", "EANTP")
dtMEANNL <- unique(dtMEANNL)

if (length(intersect(dtMEANR3$LMTNR, dtMEANNL$LMTNR))>0){
  warning(paste("Overlapping", length(intersect(dtMEANR3$LMTNR, dtMEANNL$LMTNR)), "records" ))}
dtMEANR3 <- rbind(dtMEANR3, dtMEANNL)

# Additional Mapping Mean GL - using iSynergy articles as Reference
dtMEANGL <- fread("./RAW_DATA/Gl_MAPPING.csv", colClasses = "character")
dtMEANGL[, EANTP:="Z1"]
setnames(dtMEANGL, "MATERIAL", "MATNR")
dtMEANGL[, MATNR:= str_pad(string = MATNR, width = 18, side = "left", pad = "0")]
dtMEANGL <- dtMEANGL[!LMTNR %in% dtMEANR3$LMTNR]
setkey(dtMEANGL, "MATNR", "LMTNR", "EANTP")
dtMEANGL <- unique(dtMEANGL)

if (length(intersect(dtMEANR3$LMTNR, dtMEANGL$LMTNR))>0){
  warning(paste("Overlapping", length(intersect(dtMEANR3$LMTNR, dtMEANGL$LMTNR)), "records" ))}
dtMEANR3 <- rbind(dtMEANR3, dtMEANGL)
setkey(dtMEANR3, "LMTNR")

# Quality check MEAN on Duplicates
dtMEANR3  <- dtMEANR3[, DUP:= duplicated(dtMEANR3, by = "LMTNR")]
# 60
dtTMP03  <- copy(dtMEANR3)
setkey(dtTMP03, "LMTNR", "MATNR")
dtTMP03  <- dtTMP03[, DUPA:= any(DUP)          , by = "LMTNR" ]
dtTMP03  <- dtTMP03[DUPA == TRUE ]
fWriteToSheet(dtTMP03, 
              pPath, pXLSX, "MEAN_DUP", pAppend = TRUE )

# Doubles with Sales
dtTMP04 <- dtTMP03[LMTNR %in% unique(dtDATA[MATNR %in% dtTMP03$LMTNR]$MATNR) ]
fWriteToSheet(dtTMP04, 
              pPath, pXLSX, "DOUBLES_W_SLS", pAppend = TRUE )

# take out 32 doubles with & without Sales
dtTMP05 <- dtTMP03[DUP == TRUE, .(MATNR, LMTNR)][, DEL:= "X"]
setkey(dtTMP05, "MATNR", "LMTNR")
setkey(dtMEANR3, "MATNR", "LMTNR")
dtMEANR3  <- dtTMP05[dtMEANR3][is.na(DEL), .(MATNR, LMTNR)]

# Rename MATNR -> LMTNR
setnames(dtDATA, c("MATNR"), c("LMTNR"))

# All Articles from MEAN With Sales (29424)
dtMEANR3 <- dtMEANR3[LMTNR %in% unique(dtDATA$LMTNR)]

# Articles which need a dummy 13432
dtDUMMY <- data.table(LMTNR = setdiff(unique(dtDATA$LMTNR), unique(dtMEANR3$LMTNR)))
fWriteToSheet(dtDUMMY, 
              pPath, pXLSX, "NON_MIGRATED_W_SALES", pAppend = TRUE )


# Get Master Data of Legacy Aricles to Create Dummies
dtLMTNR <- fread("./RAW_DATA/GVBNL_LMTNR.csv", colClasses = "character")
setkey(dtLMTNR, "LMTNR")

# check whether no additiona dummies are needed
dtLMTNR <- dtLMTNR[!LMTNR %in% dtMEANR3$LMTNR]
if (length(intersect(dtMEANR3$LMTNR, dtLMTNR$LMTNR))>0){
  warning(paste("Overlapping", nrow(dtDUMMY>0), "dummies needed" ))}

# check whether no additiona dummies are needed
dtDUMMY <- dtDUMMY[!LMTNR %in% unique(dtLMTNR$LMTNR)]
if (nrow(dtDUMMY)>0){
  warning(paste("Overlapping", length(intersect(dtMEANR3$LMTNR, dtLMTNR$LMTNR)), "records" ))}

# Master data of Legacy Articles to create DUMMY
dtMAT_DUM <- dtLMTNR[, DUMMY:= .GRP, 
                     by = .(MATL_TYPE, RPA_WGH3, RF_BNDID, G1RIM, G1FRMSHP, G1ITMTYP, PRCBND, TGTGRP) ]
dtMAT_DUM[, MATNR:= paste0("DNL", str_pad(DUMMY,width = 15, pad="0"))]
setkey(dtMAT_DUM, "MATNR")

dtMATNR <- rbind(dtMEANR3, dtMAT_DUM[, .(MATNR, LMTNR)])

# Join Sales data
dtDATA <- dtMATNR[dtDATA, on = "LMTNR"]
if (any(is.na(dtDATA$MATNR))){
  warning(paste("Still Dummies needed!", length(is.na(dtDATA$MATNR)), "articles" ))}

vTQ  <- sum(as.numeric(dtDATA$QUANTITY))
vPMQ <- 100 * sum(as.numeric(dtDATA[!is.na(MATNR)]$QUANTITY), na.rm = TRUE)/vTQ
vPNQ <- 100 * sum(as.numeric(dtDATA[ is.na(MATNR)]$QUANTITY), na.rm = TRUE)/vTQ

vTN  <- sum(as.numeric(dtDATA$NSITX))
vPMN <- 100 * sum(as.numeric(dtDATA[!is.na(MATNR)]$NSITX), na.rm = TRUE)/vTN
vPNN <- 100 * sum(as.numeric(dtDATA[ is.na(MATNR)]$NSITX), na.rm = TRUE)/vTN

if(fIMAGE){save.image(file = paste0("NLCL", 
                                    format(today(), "%Y%m%d"), 
                                    "_LegacyArticleToSAP", ".RData" ))}

gc()
```



```{r  Missing, echo=fECHO, eval=fEVAL}
# # MISSING !!!!
# # dtDATA[, `:=`(DOC_CURRCY     =  "EUR",
# #               UNIT           =   "ST",
# #               RETAILTYPECODE =    NA
# #                )]   # Original SC COGS
# 
# dtLMT_SALES <- dtDATA[is.na(MATNR), .N, by = .(LMTNR, SALESORG, DISTR_CHAN )]
# # join with Mapping FILE
# dtLMT_SALES <- dtDUMMY[dtLMT_SALES, on="LMTNR"]
# # dtLMTERIAL  <- dtDATA[is.na(MATNR), .N, by = .(LMTNR)]
# 
# # if(pARTGRP == "NL"){
# #   dtNAV      <- data.table(NAV = c("30" , "32" , "35" , "37" , "40" , "70"),
# #                            RPA_WGH2 = c("130", "130", "140", "140", "120", "110")) 
# #   dtLMTERIAL <- dtLMTERIAL[, NAV:= substr(LMTNR, 1, 2)]
# #   setkey(dtLMTERIAL, "NAV")
# #   dtLMTERIAL <- dtNAV[dtLMTERIAL, on = "NAV"]
# #   
# #   dtLMTERIAL <- dtLMTERIAL[is.na(RPA_WGH2), RPA_WGH2:= "170"]
# #   dtLMTERIAL <- dtLMTERIAL[, DADD:= 0]
# # } else if(pARTGRP == "CL") { 
# #   dtLMTERIAL <- dtLMTERIAL[, RPA_WGH2:= "110"]
# #   dtLMTERIAL <- dtLMTERIAL[, DADD:= 1000]
# # }
# # 
# # dtLMTERIAL <- dtLMTERIAL[, DUMMY:= .GRP, by = .(RPA_WGH2) ]
# # if (length(pARTGRP) == 1){dtLMTERIAL <- dtLMTERIAL[, DUMMY:= DUMMY + DADD ][, DADD:= NULL]}
# # dtLMTERIAL <- dtLMTERIAL[, DUMMY:= paste0("DNL", 
# #                                           str_pad(DUMMY, width = 15, pad="0"))]
# 
# # setnames(dtDUMMY, "G1LGART", "LMTNR" )
# fWriteToSheet(dtLMTERIAL, 
#               pPath, pXLSX, "DUMMIES", pAppend = TRUE )
# 
# dtMATERIAL <- dtLMTERIAL[, .N, by = .(DUMMY, RPA_WGH2)][, N:=NULL]
# setnames(dtMATERIAL, "DUMMY", "MATERIAL")
# setkey(dtMATERIAL, "MATERIAL")
# 
# dtLMTERIAL <- dtLMTERIAL[,          .(LMTNR, DUMMY)]
# setkey(dtLMTERIAL, "LMTNR")
# 
# dtMAT_SALES <- dtLMTERIAL[dtLMT_SALES, on = "LMTNR"]
# dtMAT_SALES <- dtMAT_SALES[, .N, by = .(DUMMY, SALESORG, DISTR_CHAN)][, N:=NULL]
# setnames(dtMAT_SALES, "DUMMY", "MATERIAL")
# setkey(dtMAT_SALES, "MATERIAL", "DISTR_CHAN", "SALESORG")
# 
# dtDATA <- dtLMTERIAL[dtDATA, on = "LMTNR"]
# dtDATA <- dtDATA[is.na(MATNR), MATNR:= DUMMY][, DUMMY:= NULL]

```

```{r ORDERTYPE}
dtORDTYP <- fread("./RAW_DATA/ORDERTYPE.csv")[, .(OrderType, RPA_TTC)]
setnames(dtDATA, "RPA_TTC", "OrderType")
dtDATA <- dtORDTYP[dtDATA, on = "OrderType"]
dtDATA[, OrderType:=NULL]
```

```{r EXPORT, echo=fECHO, eval=fECHO}
setnames(dtDATA,
         c("CALDAY" , "LMTNR"    , "MATNR"   , "NSITX"),
         c("SLSDATE", "G1LGART"  , "MATERIAL", "G1NTSLINT")
         )

# Select and Order the fields in the same order as the DataSource
dtDATA <- fAlignDS(pDT =  dtDATA, pDS = "G1_DS_PA_HIST_FLAT_FILE")

# dtGLAS <- fread("c:/FTP/GVBNL_GLAS.csv")

write.table(dtDATA, file = file.path("c:", "FTP", paste0("GVBNL", "_", pARTGRP, ".csv")),
            quote = TRUE     , sep = ",", na = "", dec = ".",             
            row.names = FALSE, col.names = TRUE, append = FALSE)
```


```{r EXPORT_DUMMY}
# dt0MAT_DUM = MD for 0MATERIAL Upload
# align dataset with DS
dt0MAT_DUM <-  unique(dtMAT_DUM[, .(MATNR, MATL_TYPE, RPA_WGH3, RF_BNDID, G1RIM, G1FRMSHP, G1ITMTYP) ],
                      by=NULL)

dt0MAT_DUM <- dt0MAT_DUM[, `:=`(RPA_WGH1   = "ENTERPRIS",
                                RPA_WGH2   = substr(RPA_WGH3, 1, 3), 
                                MATL_GROUP = RPA_WGH3)
                         ]
dt0MAT_DUM <- fAlignDS(pDT =  dt0MAT_DUM, pDS = "G1_DS_MD_0MATERIAL")

write.table(dt0MAT_DUM, 
            file = "C:/FTP/GVBNL_DUMMY.csv",
            quote = TRUE     , sep = ";", na = "", dec = ".",             
            row.names = FALSE, col.names = TRUE, append = FALSE)

# Select and Order the fields in the same order as the DataSource
dtMATSALES_EXP <- data.table("MATERIAL"       = dtMAT_SALES$MATERIAL,
                             "SALESORG"       = dtMAT_SALES$SALESORG,
                             "DISTR_CHAN"     = dtMAT_SALES$DISTR_CHAN,
                             "RT_PRBAND"      = NA,
                             "/BIC/G1TGTGRP1" = NA)
# dtMAT_SALES <- dtMAT_SALES[, intersect(names(dtMATERIAL), dtDS[DATASOURCE == "G1_DS_MD_0MAT_SALES", FIELDNM]),
#                            with = FALSE]

write.table(dtMATSALES_EXP, file = file.path("c:", "FTP", paste0("0MAT_SALES", "_", pARTGRP, ".csv")),
            quote = TRUE     , sep = ";", na = "", dec = ".",             
            row.names = FALSE, col.names = TRUE, append = FALSE)

```

```{r NewLink_MGH2}
# read TD + MD Article; 
# Join article
# aggregate by receipt and MGH2, 
# Join dtWGH
# aggregate sum(bit) by receipt, 
# join sum back on receipt  
source('../QAR/00_RProj/00_Global/iSynGeneral.R')

dtWGH <- data.table(
  WGH = as.character(seq(from=100, to= 190, by = 10)),
  BIT = 2^(0:9))

# dtNL1 <- fread("c:/FTP/GVBNL_CL.csv")
# dtNL2 <- fread("c:/FTP/GVBNL_GLAS.csv")

dtNL  <- rbind(fread("c:/FTP/GVBNL_CL.csv"), fread("c:/FTP/GVBNL_GLAS.csv"))
#dtNLc <- fread("C:/FTP/3. CONLONS_POS_HISTORY.csv")
dtMD <- fGetEXPTable(pTableName = "#BI0#PMATERIAL", 
                     pSystID = "BP1", pClient = 300 )
dtMD <- dtMD[, .(MATERIAL, RPA_WGH2)]
setnames(dtMD, c("RPA_WGH2"), c("WGH"))
setkey(dtMD, "MATERIAL")

# Put WGH in transaction data in order to join in next step
dtNLa <- dtMD[dtNL[, .(BILL_NUM, MATERIAL)], on="MATERIAL"][, .N, by = .(BILL_NUM, WGH)]

dtNLa <- dtWGH[dtNLa, on="WGH"]
setcolorder(dtNLa, c("BILL_NUM", "WGH", "BIT", "N"))
setkey(dtNLa, "BILL_NUM", "WGH")

dtNLa <- dtNLa[, G1WGHCMB:= sum(BIT), by = .(BILL_NUM)][, .N, by =.(BILL_NUM, G1WGHCMB)]

dtNL <- dtNLa[dtNL, on="BILL_NUM"]
dtNL[, `:=`(N = NULL)]
rm(dtNLa)

# Add Link value
dtLNK <- fread("c:/FTP/WGH_COMB.csv")
dtLNK <- dtLNK[, .(G1WGHCMB, LNK)]
dtLNK[, G1WGHCMB:= as.numeric(G1WGHCMB)]
dtNL <-  dtLNK[dtNL, on = "G1WGHCMB"]
dtNL[, G1LINKV:= NULL]
setnames(dtNL, "LNK", "G1LINKV")


### AAGCMB #####
dtAAG      <- fread("c:/SAPexport/KTGRM.csv")
dtAAG      <- dtAAG[, .(KTGRM, BIT)] 
setnames(dtAAG, c("KTGRM"), c("AAG"))

dtMTSLS      <- fGetEXPTable(pTable  = "#BI0#PMAT_SALES", pKey = c("MAT_SALES","SALESORG","DISTR_CHAN"),
                             pSystID = "BP1", pClient = "300")
dtMTSLS      <- dtMTSLS[MAT_SALES != "" & SALESORG != "" & DISTR_CHAN != "" & G1KTGRM != "", 
                        .(SALESORG, DISTR_CHAN, MAT_SALES, G1KTGRM)]
setnames(dtMTSLS, c("G1KTGRM", "MAT_SALES"), c("AAG", "MATERIAL"))

# Put AAG in transaction data in order to join in next step
dtNLa <- dtMTSLS[dtNL[, .(BILL_NUM, MATERIAL, DISTR_CHAN, SALESORG)], 
                 on= c("MATERIAL", "DISTR_CHAN", "SALESORG")][, .N, by = .(BILL_NUM, AAG)]

dtNLa <- dtAAG[dtNLa, on="AAG"]
setcolorder(dtNLa, c("BILL_NUM", "AAG", "BIT", "N"))
setkey(dtNLa, "BILL_NUM", "AAG")

dtNLa <- dtNLa[, G1AAGCMB:= sum(BIT), by = .(BILL_NUM)][, .N, by =.(BILL_NUM, G1AAGCMB)]

dtNL <- dtNLa[dtNL, on="BILL_NUM"]
dtNL[, `:=`(N = NULL)]
rm(dtNLa)

### Prepare for Export ####
dtNL <- fAlignDS(pDT =  dtNL, pDS = "G1_DS_PA_HIST_FLAT_FILE")

# dtDS <- fGetDS()
# dtNL <- dtNL[, dtDS[DATASOURCE == "G1_DS_PA_HIST_FLAT_FILE", FIELDNM], with = FALSE]
# pEXPORT <- "GVBNL_POS_HISTORY.CSV"

write.table(dtNL, 
            file = file.path("c:", "FTP", pEXPORT),
            quote = TRUE     , sep = ",", na = "", dec = ".",             
            row.names = FALSE, col.names = TRUE, append = FALSE)

```

# From here only checks 

```{r displayResult, echo=fECHO, eval=fEVAL, results='markup'}
any(is.na(dtDATA$MATERIAL))
any(is.na(dtDATA$PLANT))

# setdiff(names(dtDATA), dtDS$FIELDNM)
# setdiff(dtDS$FIELDNM , names(dtDATA))
 
dtMonths

str(dtDATA)
head(dtDATA[, c(1:5)            , with = FALSE])
head(dtDATA[, c(6:10)           , with = FALSE])
head(dtDATA[, c(11:15)          , with = FALSE])
head(dtDATA[, c(16:20)          , with = FALSE])
head(dtDATA[, c(21:ncol(dtDATA)), with = FALSE])

rm(dtDS)
```

```{r}

# dtZRAP  <- fGetZipTable("c:/ftp/ZRAPP_DATA_2016.zip", "ZRAPP_DATA_2016.txt")
# dtTWWV  <- fGetZipTable("c:/ftp/TWWV_2016.zip"      , "TWWV_2016.txt")
# dtTWGLV <- fGetZipTable("c:/ftp/TWGLV_2016.zip"     , "TWGLV_2016.txt")
# dtMALG  <- fGetZipTable("c:/ftp/MALG_2016.zip"      , "MALG_2016.txt")
# 
# 
# dtTMP02  <- dtTWGLV[, DUP:= duplicated(dtTWGLV, by = c("LAYVR", "LAYGR"))]
# dtTMP02  <- dtTMP02[, DPA:= any(DUP)          , by = c("LAYVR", "LAYGR")]
# dtTMP02  <- dtTMP02[DPA == TRUE ]
# dtTMP02  <- dtTMP02[, N:= .N, by=c("LAYVR","LAYGR")]
# View(data[1:500])




```

