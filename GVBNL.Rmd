---
title: "Legacy Sales - GrandVision Benelux - "
author: "F.J.Padt"
date: "`r Sys.Date()`"
output: 
   pdf_document:
    toc:             true
    toc_depth:       2
    number_sections: true
    fig_caption:     true
    fig_crop:        true
    highlight:       tango    
---

\newpage
![Logo](http://www.grandvision.com/img/logoGV.png) 

[DESIGN](https://projects.gvshare.com/iSynergy/01_Release_1/06._Reporting/02._Design/01._FDs/R20_POS Sales - Margin/)

```{r RSetup, echo=FALSE, eval=TRUE, cache=FALSE, results='hide'}

rm(list=ls())
gc()

source('../QAR/00_RProj/00_Global/iSynGeneral.R')

# Data Settings
fECHO    <- FALSE
fEVAL    <- TRUE
fRESULTS <- 'hide' 

# SAP systems to use
pECC_SYST <- "RP1"
pECC_CLNT <- "300"
pBI_SYST  <- "BP1" 
pBI_CLNT  <- "300"
pLGCINDC  <- "C"

# Data Settings
pOPCO     <- "GVBNL"
pARTGRP   <- c("CL")
pROWS     <- -1L
pSMALL    <- 1000
pEXMP     <- 50 
pEXP      <- FALSE
pPath     <- "./60_Results" 
pXLSX     <- paste0(pOPCO, "_SALES_", pARTGRP) 
# pEXPORT   <- paste0("POS_HISTORY" , ".csv") 

# Open Excel for storing results
if(file.exists(paste0(pPath, "/", pXLSX, ".xlsx")) == TRUE){
   file.remove(paste0(pPath, "/", pXLSX, ".xlsx"))
}

fWriteToSheet(data.frame(ECCSYST = pECC_SYST, 
                         ECCCLNT = pECC_CLNT,
                         BI_SYST = pBI_SYST ,
                         BI_CLNT = pBI_CLNT), 
              pPath, pXLSX, "PARAM", pAppend = FALSE )
```

```{r ReadRawData, echo=fECHO, eval=fEVAL}

vSORG <- c("BE01", "BE02", "BE11", "NL01", "NL02", "NL07", "NL14")
vDCHN <- c("10", "20", "30")

# Material - Read the MEAN table whcih contains the mapping
dtMEAN       <- fGetEXPTable(pTable  = "MEAN", pKey = c("MATNR", "MEINH"),
                             pSystID = pECC_SYST, pClient = pECC_CLNT)
dtMEAN       <- dtMEAN[, MATNR:= as.character(MATNR)]

# setnames(dtMEAN, "EAN11", "G1LGART")
# Site Related
# dtADRC       <- fGetEXPTable(pTable  = "ADRC", 
#                              pSystID = "RP1", pClient = "300")
# 
# dtT001W      <- fGetEXPTable(pTable  = "T001W", pKey = c("WERKS"),
#                              pSystID = "RP1", pClient = "300")

dtPLANT      <- fGetEXPTable(pTable  = "#BI0#PPLANT",
                             pKey    = "PLANT",
                             pSystID = pBI_SYST, pClient = "300")
setnames(dtPLANT, gsub("^/BIC/", "", colnames(dtPLANT)  ))

# special for NL a table with the time intervals
dtPLANTT    <- fread(input = "./RAW_DATA/GVBNL_PLANTT.csv", sep = ";",
                     colClasses = "character", stringsAsFactors = FALSE)

# dtSDP_BLX    <- fread(file.path(".", "RAW_DATA", "SDP_BLX.csv"), 
#                       sep=";", colClasses = "character")
# setkey(dtSDP_BLX, "WERKS")
# dtSDP_BLX[, `:=`(DISTR_CHAN = "10", G1LGSTNO = NULL)]

#Load transactional data
dtDATA     <- fread(file.path(".", "RAW_DATA", "GVBLX_HIST.txt"),  
                    sep = ";", nrows = pROWS, colClasses="character") 
# dtDATA     <- dtDATA[article_group %in% pARTGRP, ]

# dtDATA       <- fread(file.path(".", "RAW_DATA", "ttSalesHist.prd.20150720.csv"), 
#                     sep=";", colClasses="character")
# dtDATA <- dtDATA[, ART:= gsub("\"", "", dtDATA[1]$Art.nr.)]

l_months <- sort(unique(substr(dtDATA$invoice_date, 1, 6)))
dtMonths <- dtDATA[, .N, by=.(substr(dtDATA$invoice_date, 1, 6))]

setnames(
  dtDATA,
  c("invoice_date", "store"         , "invoice_number" ,
    "order_type"  , "article_number", "discount_reason", 
    "link"        , "quantity"      , "discount"       , 
    "tax_amount"  , "cost_amount"   , "net_sales_incl_tax",
    "wholesale_price"),
  c("CALDAY"     , "G1LGSTNO"       , "BILL_NUM"       , 
    "RPA_TTC"     , "MATNR"         , "RPA_DRC"        , 
    "G1LINKV"     , "QUANTITY"      , "G1DISCIT"       , 
    "TAX_AMOUNT"  , "RETPRCOST"     , "NSITX",
    "RETTRCOST"))

# dtNLCL <- unique(dtDATA[, .(MATNR, article_group)])
# setnames(dtNLCL, c("MATNR", "article_group"), c("LMTNR", "TYPE"))
# 
# setnames(dtMEAN, "EAN11", "LMTNR")
# 
# dtNLCL <- merge(dtNLCL, dtMEAN[EANTP == "Z1", .(MATNR, LMTNR)],
#                 by = "LMTNR", all.x = TRUE)
# setnames(dtMEAN, "LMTNR", "EAN11")
# 
# setkey(dtNLCL, "MATNR")
# save(dtNLCL, file = "dtNLCL.RData")
# 
# write.table(dtNLCL, 
#             file = "C:/FTP/GVBNL_NLCL.csv",
#             quote = TRUE     , sep = ";", na = "", dec = ".",             
#             row.names = FALSE, col.names = TRUE, append = FALSE)
```

# Historical Data #

The historical data for `r pOPCO` is extracted from Navison as one big data set. 
This set is turned into a  subset of the standard SAP extractor 
2LIS_13_VDITM which is used in the iSynery Project.

From:    `r min(dtDATA$SLSDATE)` 
To:      `r max(dtDATA$SLSDATE)`
Records: `r nrow(dtDATA)`

## Source Data 

```{r PrepareDataSet, echo=fECHO, eval=fEVAL, results=fRESULTS}
# check for Invalid Article numbers 
# 20160128 - 2178 records
dtTMP01 <- dtDATA[MATNR  == " " |
                  MATNR  == ""  |  
                  (MATNR == 0)  ] 

nrow(dtDATA)
dtDATA <- dtDATA[MATNR %in% dtTMP01$MATNR, MATNR:= "GVBNL0000000000000"]
nrow(dtDATA)

fWriteToSheet(dtTMP01, 
              pPath, pXLSX, "MATNR_MISSING", pAppend = TRUE)

# recode MATNR 00000000 to Z00000000 temporarily as leading zero's are removed 
dtDATA <- dtDATA[MATNR == "00000000", MATNR:= "Z00000000"]

# remove leading zero's
dtDATA <- dtDATA[, MATNR:= gsub("(^|[^0-9])0+", "\\1", MATNR, perl = TRUE)]

# recode MATNR 00000000 to Z00000000 temporarily as leading zero's are removed 
dtDATA <- dtDATA[MATNR == "Z00000000", MATNR:= "00000000"]

gc()

save(dtDATA, file = "NLCL20160428.RData" )
save.image(file = paste0("NLCL", format(today(), "%Y%m%d"), "_PrepareDataSet", ".RData" ))
```

Below the structure of the source data and the number of records is displayed

```{r displayDetailMean, echo=fECHO, eval=fEVAL, results='markup'}

str(dtDATA)
head(dtDATA[, c(1:7)             , with = FALSE])
head(dtDATA[, c(8 :ncol(dtDATA)) , with = FALSE])

# fWriteToSheet(as.data.frame(str(dtDATA)), pFILE, "Structure", pAppend = TRUE)
fWriteToSheet(head(dtDATA[1:pEXMP]), 
               pPath, pXLSX, "EXAMPLE_DATA_BEFORE"   , pAppend = TRUE)
```

```{r ChangeDataTypes, echo=fECHO, eval=fEVAL, results=fRESULTS}
# Change data Types and set NA to 0 !!!!  700secs. !!!!
system.time(
  dtDATA <- dtDATA[, `:=`(
    BILL_NUM       = paste0("H", 
                            str_pad(G1LGSTNO, 3, pad ="0", side = "left"), 
                            str_pad(BILL_NUM, 6, pad ="0", side = "left")),
    RPA_DRC        = toupper(x = RPA_DRC),
    G1LGSTNO       = str_pad(G1LGSTNO, 3, pad ="0"),
    QUANTITY       = ifelse(is.na(QUANTITY)  , 0, as.integer(QUANTITY)),
    NSITX          = ifelse(is.na(NSITX)     , 0, as.numeric(sub(",", ".", NSITX))),
    G1DISCIT       = ifelse(is.na(G1DISCIT)  , 0, as.numeric(sub(",", ".", G1DISCIT))),
    TAX_AMOUNT     = ifelse(is.na(TAX_AMOUNT), 0, as.numeric(sub(",", ".", TAX_AMOUNT))),
    RETPRCOST      = ifelse(is.na(RETPRCOST) , 0, as.numeric(sub(",", ".", RETPRCOST))), 
    ORGSCCOST      = ifelse(is.na(RETPRCOST) , 0, as.numeric(sub(",", ".", RETPRCOST))),
    RETTRCOST      = ifelse(is.na(RETTRCOST) , 0, as.numeric(sub(",", ".", RETTRCOST ))),
    DOC_CURRCY     = "EUR",
    UNIT           = "ST",
    RETAILTYPECODE =  NA,
    G1LISLINT      =  0,
    G1LOFLAG       =  NA,
    G1SPECFG       =  NA,
    G1WGHCMB       =  NA
    ) ]
  )

dtDATA <- dtDATA[, `:=`(NETVAL_INV = NSITX - TAX_AMOUNT)]
setkey(dtDATA, "BILL_NUM")

# Generate BILL_ITEM
system.time(
  dtDATA <- dtDATA[, BILL_ITEM:= str_pad(seq(from = 1, to = .N, by = 1), 
                                       width = 5, pad = "0"), 
                 by=c("BILL_NUM", "G1LGSTNO", "CALDAY")])

fWriteToSheet(head(dtDATA[1:pEXMP]), 
               pPath, pXLSX, "EXAMPLE_DATA_AFTER"   , pAppend = TRUE)
# save(dtDATA, file = paste0("dtDATA_", pARTGRP, ".RData"))

gc()

save(dtDATA,file = "NLCL20160428.RData" )
save.image(file = paste0("NLCL", format(today(), "%Y%m%d"), "_ChangeDataTypes", ".RData" ))
```

### Data Preparation

The column names of the GVBNL data are changed to the BI object names for Mapping.
Secondly the decimal separator ',' is replaced by a '.'.
Finally non-existing key figures or set to 0.

```{r displayDetailMean2, echo=fECHO, eval=fEVAL, results='markup'}
str(dtDATA)
head(dtDATA)
# save.image(file = "intermed.RData")
# load(file = "intermed.RData")
```

### Data Source

```{r LegacyStoreToSAP, echo=fECHO, results=fRESULTS}

dtPLANT     <- dtPLANT[PLANTCAT == "A" & !(substr(PLANT, 1, 1) %in% c("Y", "Z"))
                       ][, `:=`(PLANTCAT = NULL, SYSTID = NULL)]

# add the iSynergy Store next to the legacy store

# PLANT
dtPLANT <- dtPLANT[SALESORG %in% c("NL01", "BE01", "NL02", "BE02", "NL14", "NL07") ]
setkey(dtPLANT, PLANT)

# Remove the "/BIC/" prefix
setnames(dtPLANT, gsub("^/BIC/", "", colnames(dtPLANT)))

dtPLANT <- dtPLANT[, CHK:= substr(G1LGSTNO, nchar(G1LGSTNO)-2, nchar(G1LGSTNO))]
dtPLANT <- dtPLANTT[dtPLANT, on = c("PLANT", "CHK"), .(PLANT, G1LGSTNO, SALESORG, DISTR_CHAN, CHK, FROM)]
dtPLANT <- dtPLANT[, `:=`(G1LGSTNO = CHK, CHK = NULL)]
dtPLANT <- dtPLANT[is.na(FROM), FROM:= "10000101"]

# Quality check on duplicate Legacy Stores
dtTMP02  <- copy(dtPLANT)
dtTMP02  <- dtTMP02[, DUP:= duplicated(dtTMP02, by = "G1LGSTNO")]
dtTMP02  <- dtTMP02[, DUP:= any(DUP)          , by = "G1LGSTNO" ]
dtTMP02  <- dtTMP02[DUP == TRUE ]
setkey(dtTMP02, "G1LGSTNO", "FROM") 

fWriteToSheet(dtTMP02, 
              pPath, pXLSX, "PLANT_DUP", pAppend = TRUE )

# check If any closed stores missing
dtTMP03 <- data.table(
  SALES_WO_SITE   = setdiff(unique(dtDATA$G1LGSTNO), dtPLANT$G1LGSTNO))
fWriteToSheet(dtTMP03, 
              pPath, pXLSX, "SALES_WO_SITE", pAppend = TRUE )

# Check Sites without sales, could be new
dtTMP04 <- data.table(
  SITE_WO_SALES = setdiff(dtPLANT$G1LGSTNO       , unique(dtDATA$G1LGSTNO)))
fWriteToSheet(dtTMP04, 
              pPath, pXLSX, "SITE_WO_POS_SALES", pAppend = TRUE )

# Map the data Of the Legacy Stores
setnames(dtPLANT, "FROM", "CALDAY")
system.time(
  dtDATA <- dtPLANT[dtDATA, roll = TRUE, rollends = TRUE, 
               on = c("G1LGSTNO", "CALDAY")])

save(dtDATA,file = "NLCL20160428.RData" )
save.image(file = paste0("NLCL", format(today(), "%Y%m%d"), "_LegacyStoreToSAP", ".RData" ))
# rm(dtTMP02, dtTMP03, dtTMP04, dtPLANT, dtPLANTT)



# ---------------------------------------------------------
# # only relevant Sites
# dtPLANT <- dtPLANT[!PLANT   %in% c("0000", "")]
# 
# # Allign with ECC Logic
# dtPLANT <- dtPLANT[nchar(G1LGSTNO) != 4 & 
#                    !is.na(G1LGSTNO) &
#                      G1LGSTNO != ""]
# 
# l_G1LGSTNO <- unique(substr(dtDATA$WERKS, 2, 4))
# dtTMP11    <- data.frame(DIFF = setdiff(l_G1LGSTNO      , dtPLANT$G1LGSTNO))  # In sales but not in master data
# dtTMP12    <- data.frame(DIFF = setdiff(dtPLANT$G1LGSTNO, l_G1LGSTNO))        # In master data but not in Sales
# # # add the iSynergy Store next to the legacy store
# # setnames(dtADRC, "ADDRNUMBER", "ADRNR")
# # 
# # dtWERKS  <- merge(dtT001W[ , .(ADRNR, WERKS, VKORG, VTWEG, VLFKZ)], 
# #                   dtADRC[  , .(ADRNR, SORT2)],
# #                   all.x = TRUE, by = "ADRNR")
# # 
# # # Select only NL stores
# # dtWERKS  <- dtWERKS[substr(VKORG, 1, 2) %in% c("NL", "BE")] 
# # 
# # # Remove stores which are not Mapped
# # dtWERKS <- dtWERKS[SORT2 == "", SORT2 := NA]
# # dtTMP01  <- dtWERKS[ is.na(SORT2)][, SORT2:= NULL]
# # fWriteToSheet(dtTMP01, 
# #               pPath, pXLSX, "WERKS_NO_SORT2", pAppend = TRUE )
# # 
# # dtWERKS  <- dtWERKS[!is.na(SORT2)] 
# 
# # Add Sales Org from list which include the closed Stores
# dtSDP_01 <- copy(dtSDP_BLX[, SORT2:= substr(WERKS, 2, 4)])
# setnames(dtSDP_01, c("WERKS"), c("G1LGSTNO"))
# fWriteToSheet(dtSDP_01, 
#               pPath, pXLSX, "LegacyStore_incl_Closed", pAppend = TRUE )
# 
# dtWERKS   <- merge(dtWERKS, 
#                    dtSDP_01, 
#                    all.y = TRUE, by = "SORT2" )
# 
# # stores With Sales
# dtTMP03 <- dtWERKS[!(G1LGSTNO %in% unique(dtDATA$G1LGSTNO))]
# fWriteToSheet(dtTMP03, 
#               pPath, pXLSX, "WERKS_WO_SLS", pAppend = TRUE )
# 
# dtWERKS <- dtWERKS[G1LGSTNO %in% unique(dtDATA$G1LGSTNO)]
# 
# # Quality check on Duplicates
# dtWERKS  <- dtWERKS[, DUP:= duplicated(dtWERKS, by = "SORT2")]
# 
# dtTMP02  <- copy(dtWERKS)
# dtTMP02  <- dtTMP02[, DUP:= any(DUP)          , by = "SORT2" ]
# dtTMP02  <- dtTMP02[DUP == TRUE ]
# fWriteToSheet(dtTMP02, 
#               pPath, pXLSX, "WERKS_DUP", pAppend = TRUE )
# fWriteToSheet(dtWERKS[DUP == TRUE], 
#               pPath, pXLSX, "G1LGSTNO_DEL", pAppend = TRUE )
# 
# dtWERKS  <- dtWERKS[DUP == FALSE][, DUP:=NULL]
# dtWERKS  <- dtWERKS[, .(WERKS, G1LGSTNO, SALESORG, DISTR_CHAN)]
# 
# # Add the iSynergy Site to the Data Set based upon Legacy site  
# setnames(dtDATA, c("WERKS"), c("G1LGSTNO"))
# 
# # Create List of Dummy stores which are not used
# setnames(dtPLANT, c("/BIC/G1LGSTNO"), c("G1LGSTNO"))
# l_DUMMIES_USED <- dtPLANT[substr(PLANT,1,1) == pLGCINDC, .(PLANT, G1LGSTNO)]
# l_DUMMIES_LIST <- paste0(pLGCINDC, str_pad(1:1000, 3, pad ="0"))
# l_DUMMIES_LIST <- setdiff(l_DUMMIES_LIST, l_DUMMIES_USED )
# 
# # Introduce dummy stores for closed stores which are not in iSYnergy
# l_WERKS <- nrow(dtWERKS[is.na(WERKS)])
# dtWERKS <- dtWERKS[is.na(WERKS), 
#                    WERKS:= paste0(pLGCINDC, 
#                                   str_pad(100:(99 + l_WERKS), 3, pad ="0"))]
# fWriteToSheet(dtWERKS, 
#               pPath, pXLSX, "SITE_MAPPING", pAppend = TRUE )
# 
# dtDATA  <- merge(dtWERKS, dtDATA, 
#                  all.y = TRUE, by = "G1LGSTNO")


```

## Store Mapping

Following Stores could not be mapped and are removed from the store Master Data:

```{r Non-Mapped_Stores, echo=fECHO, eval=fEVAL, results=fRESULTS}
# dtTMP01
# dtTMP02
# 
# rm(dtWERKS , dtPLANT , dtADRC , dtT001W, 
#    dtTMP01 , dtTMP02 , dtTMP03, dtTMP04, 
#    dtSDP_VE, dtSDP_01, l_DUMMIES_USED)
# gc()
```


```{r LegacyArticleToSAP, echo=fECHO, eval=fEVAL }
# add the iSynergy Article next to the legacy article
dtMATNR <- dtMEAN[MEINH == "ST" & 
                  EANTP == "Z1" &
                  EAN11 != "DUPLICATE", 
                  .(MATNR, EAN11, EANTP)]
setnames(dtMATNR, c("EAN11"), c("LMTNR"))

# Quality check on Duplicates
dtMATNR  <- dtMATNR[, DUP:= duplicated(dtMATNR, by = "LMTNR")]

dtTMP03  <- copy(dtMATNR)
setkey(dtTMP03, "LMTNR", "MATNR")
dtTMP03  <- dtTMP03[, DUPA:= any(DUP)          , by = "LMTNR" ]
dtTMP03  <- dtTMP03[DUPA == TRUE ]
fWriteToSheet(dtTMP03, 
              pPath, pXLSX, "MEAN_DUP", pAppend = TRUE )

# Doubles with Sales
dtTMP04 <- dtTMP03[LMTNR %in% unique(dtDATA[MATNR %in% dtTMP03$LMTNR]$MATNR) ]
fWriteToSheet(dtTMP04, 
              pPath, pXLSX, "DOUBLES_W_SLS", pAppend = TRUE )

# take out doubles with & without Sales
dtTMP05 <- dtTMP03[DUP == TRUE, .(MATNR, LMTNR)][, DEL:= "X"]
setkey(dtTMP05, "MATNR", "LMTNR")
setkey(dtMATNR, "MATNR", "LMTNR")
dtMATNR  <- dtTMP05[dtMATNR][is.na(DEL), .(MATNR, LMTNR)]

# Rename MATNR -> LMTNR
setnames(dtDATA, c("MATNR"), c("LMTNR"))

# All Articles from MEAN With Sales (28811)
dtMATNR <- dtMATNR[LMTNR %in% unique(dtDATA$LMTNR)]

# Aricles which are not Migrated
dtDUMMY <- data.table(LMTNR = setdiff(unique(dtDATA$LMTNR), unique(dtMATNR$LMTNR)))
fWriteToSheet(dtDUMMY, 
              pPath, pXLSX, "NON_MIGRATED_W_SALES", pAppend = TRUE )


# Make Dummy Mapping
# Master data of Legacy Articles to create DUMMY
dtLMTNR <- fread("./RAW_DATA/GVBNL_LMTNR.csv", colClasses = "character")
setkey(dtLMTNR, "LMTNR")

dtMAT_DUM <- dtLMTNR[, DUMMY:= .GRP, 
                   by = .(MATL_TYPE, RPA_WGH3, RF_BNDID, G1RIM, G1FRMSHP, G1ITMTYP, PRCBND, TGTGRP) ]
dtMAT_DUM[, MATERIAL:= paste0("DNL", str_pad(DUMMY,width = 15, pad="0"))]
setkey(dtMAT_DUM, "MATERIAL")

#dtMAT_DUM = MD for 0MATERIAL Upload
dtMAT_DUM <- dtMAT_DUM[, .N, 
                     by = .(MATERIAL, MATL_TYPE, RPA_WGH3, RF_BNDID, G1RIM, G1FRMSHP, G1ITMTYP)][, N:=NULL]

dtMAT_DUM <- dtMAT_DUM[, `:=`(RPA_WGH1   = "ENTERPRIS",
                              RPA_WGH2   = substr(RPA_WGH3, 1, 3), 
                              MATL_GROUP = RPA_WGH3
                              )
                       ]
# align dataset with DS
dtMAT_DUM <- fAlignDS(pDT =  dtMAT_DUM, pDS = "G1_DS_MD_0MATERIAL")

# check If any Articles are both Dummy and in Mean
# dtTMP06 <- data.table(DUMMY_MISSING    = setdiff(unique(dtDUMMY$LMTNR)  , unique(dtLMTNR$LMTNR)))
# dtTMP07 <- data.table(MEAN_NOT_DUMMY   = setdiff(unique(dtLMTNR$LMTNR)  , unique(dtDUMMY$LMTNR)))
# dtTMP08 <- data.table(LMTNR_AND_DUMMY  = intersect(unique(dtLMTNR$LMTNR), unique(dtDUMMY$LMTNR)))
# dtTMP09 <- data.table(MATNR_AND_LMTNR  = intersect(unique(dtMATNR$LMTNR), unique(dtLMTNR$LMTNR)))

dtLMTNR <- dtLMTNR[!LMTNR %in% unique(dtMATNR$LMTNR)]
dtDUMMY <- dtDUMMY[!LMTNR %in% unique(dtLMTNR$LMTNR)]

# Missing Dummies
lTMP07 <- setdiff(unique(dtLMTNR$LMTNR), unique(dtDUMMY$LMTNR) )
lTMP08 <- setdiff(unique(dtTMP06$LMTNR), unique(dtLMTNR$LMTNR) )

dtTMP07 <- dtDATA[LMTNR %in% lTMP08, sum(QUANTITY), by= .(LMTNR, article_group)]
dtTMP07 <- dtTMP07[article_group == "CL", `:=`(MATNR = "DNL0000000000000CL")]
dtTMP07 <- dtTMP07[article_group == "NL", `:=`(MATNR = "DNL0000000000000NL")]

dtDUM_UKN <- data.table(
  MATERIAL   = c("DNL0000000000000CL", "DNL0000000000000NL"),
  RPA_WGH1   = "ENTERPRIS",
  RPA_WGH2   = c("110", "130")
)

# align dataset with DS
dtDUM_UKN <- fAlignDS(pDT =  dtDUM_UKN, pDS = "G1_DS_MD_0MATERIAL")

dtDM_GL <- data.table(MATERIAL   = c("DNL000000000900263", 
                                     "DNL000000000900268", 
                                     "DNL000000000900277",
                                     "DNL000000000900276"),
                      MATL_TYPE  = "Z002",                      
                      RPA_WGH1   = "ENTERPRIS",
                      RPA_WGH2   = "100",
                      RPA_WGH3   = c("100101", 
                                     "100103",
                                     "100102",
                                     "100104"),
                      MATL_GROUP = c("100101", 
                                     "100103",
                                     "100102",
                                     "100104")
)

# align dataset with DS
dtDM_GL <- fAlignDS(pDT =  dtDM_GL, pDS = "G1_DS_MD_0MATERIAL")

dt0MAT_DUM <- rbind(dtMAT_DUM, dtDUM_UKN, dtDM_GL)

dtDATA <- dtMATNR[dtDATA, on = "LMTNR"]
# fWriteToSheet(dtTMP07, 
#               pPath, pXLSX, "NON_MIGRATED_W_SALES3", pAppend = TRUE )

write.table(dt0MAT_DUM, 
            file = "C:/FTP/GVBNL_DUMMY.csv",
            quote = TRUE     , sep = ";", na = "", dec = ".",             
            row.names = FALSE, col.names = TRUE, append = FALSE)

# Create the Complete MAterial Mapping Table
# MEAN, DUMMY, UNKNOWN & GLAS
setnames(dtDUMMY, c("MATERIAL"), c("MATNR"))
dtDUMMY <- dtDUMMY[, names(dtMATNR), with = FALSE]
dtTMP07 <- dtTMP07[, names(dtMATNR), with = FALSE]

dtMATNR <- rbind(dtMATNR, dtDUMMY, dtTMP07)
dtMATNR <- dtMATNR[, DUP := duplicated(dtMATNR, by = "LMTNR")]
dtMATNR <- dtMATNR[, DUPA:= any(DUP), by = "LMTNR" ]
dtMATNR <- dtMATNR[!(DUPA == TRUE & substr(MATNR,1,3) == "DNL")]

# Map Material Again
dtDATA[, MATNR:=NULL]
dtDATA  <- dtMATNR[dtDATA, on = "LMTNR"]


# fWriteToSheet(dtDATA[is.na(MATNR)], 
#               pPath, pXLSX, "NON_MIGRATED_SALES", pAppend = TRUE )

vTQ  <- sum(as.numeric(dtDATA$QUANTITY))
vPMQ <- 100 * sum(as.numeric(dtDATA[!is.na(MATNR)]$QUANTITY), na.rm = TRUE)/vTQ
vPNQ <- 100 * sum(as.numeric(dtDATA[ is.na(MATNR)]$QUANTITY), na.rm = TRUE)/vTQ

vTN  <- sum(as.numeric(dtDATA$NSITX))
vPMN <- 100 * sum(as.numeric(dtDATA[!is.na(MATNR)]$NSITX), na.rm = TRUE)/vTN
vPNN <- 100 * sum(as.numeric(dtDATA[ is.na(MATNR)]$NSITX), na.rm = TRUE)/vTN

save.image(file = paste0("NLCL", format(today(), "%Y%m%d"), "_LegacyArticleToSAP", ".RData" ))

dtNLCL <- dtDATA
save(dtNLCL, file = paste0("NLCL", format(today(), "%Y%m%d"), ".RData"))

rm(dtMATNR, dtMEAN)
gc()
```

```{r  Missing, echo=fECHO, eval=fEVAL}
# MISSING !!!!
# dtDATA[, `:=`(DOC_CURRCY     =  "EUR",
#               UNIT           =   "ST",
#               RETAILTYPECODE =    NA
#                )]   # Original SC COGS

dtLMT_SALES <- dtDATA[is.na(MATNR), .N, by = .(LMTNR, SALESORG, DISTR_CHAN )]
# join with Mapping FILE
dtLMT_SALES <- dtDUMMY[dtLMT_SALES, on="LMTNR"]
# dtLMTERIAL  <- dtDATA[is.na(MATNR), .N, by = .(LMTNR)]

# if(pARTGRP == "NL"){
#   dtNAV      <- data.table(NAV = c("30" , "32" , "35" , "37" , "40" , "70"),
#                            RPA_WGH2 = c("130", "130", "140", "140", "120", "110")) 
#   dtLMTERIAL <- dtLMTERIAL[, NAV:= substr(LMTNR, 1, 2)]
#   setkey(dtLMTERIAL, "NAV")
#   dtLMTERIAL <- dtNAV[dtLMTERIAL, on = "NAV"]
#   
#   dtLMTERIAL <- dtLMTERIAL[is.na(RPA_WGH2), RPA_WGH2:= "170"]
#   dtLMTERIAL <- dtLMTERIAL[, DADD:= 0]
# } else if(pARTGRP == "CL") { 
#   dtLMTERIAL <- dtLMTERIAL[, RPA_WGH2:= "110"]
#   dtLMTERIAL <- dtLMTERIAL[, DADD:= 1000]
# }
# 
# dtLMTERIAL <- dtLMTERIAL[, DUMMY:= .GRP, by = .(RPA_WGH2) ]
# if (length(pARTGRP) == 1){dtLMTERIAL <- dtLMTERIAL[, DUMMY:= DUMMY + DADD ][, DADD:= NULL]}
# dtLMTERIAL <- dtLMTERIAL[, DUMMY:= paste0("DNL", 
#                                           str_pad(DUMMY, width = 15, pad="0"))]

# setnames(dtDUMMY, "G1LGART", "LMTNR" )
fWriteToSheet(dtLMTERIAL, 
              pPath, pXLSX, "DUMMIES", pAppend = TRUE )

dtMATERIAL <- dtLMTERIAL[, .N, by = .(DUMMY, RPA_WGH2)][, N:=NULL]
setnames(dtMATERIAL, "DUMMY", "MATERIAL")
setkey(dtMATERIAL, "MATERIAL")

dtLMTERIAL <- dtLMTERIAL[,          .(LMTNR, DUMMY)]
setkey(dtLMTERIAL, "LMTNR")

dtMAT_SALES <- dtLMTERIAL[dtLMT_SALES, on = "LMTNR"]
dtMAT_SALES <- dtMAT_SALES[, .N, by = .(DUMMY, SALESORG, DISTR_CHAN)][, N:=NULL]
setnames(dtMAT_SALES, "DUMMY", "MATERIAL")
setkey(dtMAT_SALES, "MATERIAL", "DISTR_CHAN", "SALESORG")

dtDATA <- dtLMTERIAL[dtDATA, on = "LMTNR"]
dtDATA <- dtDATA[is.na(MATNR), MATNR:= DUMMY][, DUMMY:= NULL]

```

```{r EXPORT, echo=fECHO, eval=fECHO}
dtDS <- fGetDS()

setnames(dtDATA,
         c("CALDAY" , "LMTNR"    , "MATNR"   , "NSITX"),
         c("SLSDATE", "G1LGART"  , "MATERIAL", "G1NTSLINT")
         )

setdiff(names(dtDATA), dtDS[DATASOURCE == "G1_DS_PA_HIST_FLAT_FILE", FIELDNM])
setdiff(dtDS[DATASOURCE == "G1_DS_PA_HIST_FLAT_FILE", FIELDNM] , names(dtDATA))

# Select and Order the fields in the same order as the DataSource
# dtDATA <- dtDATA[, dtDS$FIELDNM, with = FALSE]
dtDATA <- dtDATA[, dtDS[DATASOURCE == "G1_DS_PA_HIST_FLAT_FILE", FIELDNM], with = FALSE]

write.table(dtDATA, file = file.path("c:", "FTP", paste0("GVBNL", "_", pARTGRP, ".csv")),
            quote = TRUE     , sep = ",", na = "", dec = ".",             
            row.names = FALSE, col.names = TRUE, append = FALSE)

# Select and Order the fields in the same order as the DataSource
dtMATERIAL_EXP <- data.table("MATERIAL"       = dtMATERIAL$MATERIAL,
                             "MATL_TYPE"      = NA,
                             "RPA_WGH1"       = "ENTERPRIS",
                             "RPA_WGH2"       = dtMATERIAL$RPA_WGH2,
                             "RPA_WGH3"       = NA,
                             "MATL_GROUP"     = NA,
                             "RF_BNDID"       = NA,
                             "/BIC/G1BRNDTY"  = NA,
                             "/BIC/G1COLOR"   = NA,
                             "/BIC/G1REFINX1" = NA, 
                             "/BIC/G1LENCTY"  = NA,
                             "/BIC/G1TRANS"   = NA,  
                             "/BIC/G1POLAR"   = NA )
# dtMATERIAL <- dtMATERIAL[, intersect(names(dtMATERIAL), dtDS[DATASOURCE == "G1_DS_MD_0MATERIAL", FIELDNM]), 
#                          with = FALSE]

write.table(dtMATERIAL_EXP, file = file.path("c:", "FTP", paste0("0MATERIAL", "_", pARTGRP, ".csv")),
            quote = TRUE     , sep = ";", na = "", dec = ".",             
            row.names = FALSE, col.names = TRUE, append = FALSE)

# Select and Order the fields in the same order as the DataSource
dtMATSALES_EXP <- data.table("MATERIAL"       = dtMAT_SALES$MATERIAL,
                             "SALESORG"       = dtMAT_SALES$SALESORG,
                             "DISTR_CHAN"     = dtMAT_SALES$DISTR_CHAN,
                             "RT_PRBAND"      = NA,
                             "/BIC/G1TGTGRP1" = NA)
# dtMAT_SALES <- dtMAT_SALES[, intersect(names(dtMATERIAL), dtDS[DATASOURCE == "G1_DS_MD_0MAT_SALES", FIELDNM]),
#                            with = FALSE]

write.table(dtMATSALES_EXP, file = file.path("c:", "FTP", paste0("0MAT_SALES", "_", pARTGRP, ".csv")),
            quote = TRUE     , sep = ";", na = "", dec = ".",             
            row.names = FALSE, col.names = TRUE, append = FALSE)


```


```{r displayResult, echo=fECHO, eval=fEVAL, results='markup'}
any(is.na(dtDATA$MATERIAL))
any(is.na(dtDATA$PLANT))

# setdiff(names(dtDATA), dtDS$FIELDNM)
# setdiff(dtDS$FIELDNM , names(dtDATA))
 
dtMonths

str(dtDATA)
head(dtDATA[, c(1:5)            , with = FALSE])
head(dtDATA[, c(6:10)           , with = FALSE])
head(dtDATA[, c(11:15)          , with = FALSE])
head(dtDATA[, c(16:20)          , with = FALSE])
head(dtDATA[, c(21:ncol(dtDATA)), with = FALSE])

rm(dtDS)
```

```{r}

# dtZRAP  <- fGetZipTable("c:/ftp/ZRAPP_DATA_2016.zip", "ZRAPP_DATA_2016.txt")
# dtTWWV  <- fGetZipTable("c:/ftp/TWWV_2016.zip"      , "TWWV_2016.txt")
# dtTWGLV <- fGetZipTable("c:/ftp/TWGLV_2016.zip"     , "TWGLV_2016.txt")
# dtMALG  <- fGetZipTable("c:/ftp/MALG_2016.zip"      , "MALG_2016.txt")
# 
# 
# dtTMP02  <- dtTWGLV[, DUP:= duplicated(dtTWGLV, by = c("LAYVR", "LAYGR"))]
# dtTMP02  <- dtTMP02[, DPA:= any(DUP)          , by = c("LAYVR", "LAYGR")]
# dtTMP02  <- dtTMP02[DPA == TRUE ]
# dtTMP02  <- dtTMP02[, N:= .N, by=c("LAYVR","LAYGR")]
# View(data[1:500])




```

